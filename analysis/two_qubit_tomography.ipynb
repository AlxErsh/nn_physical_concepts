{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scinet import *\n",
    "import scinet.ed_quantum as edq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train models\n",
    "\n",
    "*Warning:* Training the required number of models takes a significant amount of time on a standard laptop. If you would like to download the pre-trained models and corresponding (validation) datasets instead (not included here because of large file size), you can do so [here](https://github.com/eth-nn-physics/quantum_data). To use these models, copy the contents of the downloaded `data` directory and `tf_save` directory into the corresponding directories of this project.\n",
    "\n",
    "### Parameters\n",
    "- `latent_size:` between 0 and 9\n",
    "- `input_size: 30`\n",
    "- `input2_size: 30`\n",
    "- `output_size: 1`\n",
    "- `encoder_num_units`: [300, 100]\n",
    "- other parameters: default values\n",
    "### Data\n",
    "Both the qubit and the projection axis are specified by 30 random projective measurements.\n",
    "- training data: 490000 samples\n",
    "- validation data: 10000 samples\n",
    "\n",
    "### Training\n",
    "For each latent size, eight training runs are performed and the one with the lowest error is chosen. Each training run is performed in two steps:\n",
    "    1. `epoch_num: 250`, `batch_size: 512`, `learning_rate: 1e-3`, `beta: 1e-5`\n",
    "    2. `epoch_num: 50`, `batch_size: 512`, `learning_rate: 1e-4`, `beta: 1e-5`\n",
    "    \n",
    "### Naming scheme\n",
    "The models are named 'two_qubits_label_s_i', where label is 'comp' (for tomographically complete) or '*n*dim_incomp' (for tomographically incomplete with *n* orhtogonal projectors), 's' is the number of latent neurons and 'i' is the run. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for inc_tom_m1 in [2, 3, False]:\n",
    "#     if inc_tom_m1 is False:\n",
    "#         label = 'comp'\n",
    "#     elif inc_tom_m1 == 2:\n",
    "#         label = '2dim_incomp'\n",
    "#     elif inc_tom_m1 == 3:\n",
    "#         label = '3dim_incomp'\n",
    "#     dataset_name = 'two_qubits_{}'.format(label)\n",
    "#     edq.create_data(2, 30, 30, 500000, dataset_name, incomplete_tomography=[inc_tom_m1, False])\n",
    "#     td, vd, ts, vs, projectors = dl.load(2, dataset_name)\n",
    "#     for s in range(10):\n",
    "#         for i in range(3):\n",
    "#             print \"Tomography case:\", label\n",
    "#             print \"Running iteration \", i\n",
    "#             print 'Using {} latent neurons'.format(s)\n",
    "#             name = 'two_qubits_{}_{}_{}'.format(label, s, i)\n",
    "#             net = nn.Network(30, s, 30, 1, name=name, encoder_num_units=[300, 100], decoder_num_units=[100, 100])\n",
    "#             net.train(250, 512, 1e-3, td, vd, beta_fun=lambda x: 1.e-5, test_step=10)\n",
    "#             net.train(50, 512, 1e-4, td, vd, beta_fun=lambda x: 1.e-5, test_step=10)\n",
    "#             net.save(name)\n",
    "#             ra = net.run(vd, net.recon_loss)\n",
    "#             print \"Error: \", ra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load trained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "err = []\n",
    "for label in ['2dim_incomp', '3dim_incomp', 'comp']:\n",
    "    err_label = []\n",
    "    for i in range(3):\n",
    "        # if you have downloaded the validation data set from the link above:\n",
    "        td, vd, ts, vs, projectors = dl.load(100, 'two_qubits_{}_validation'.format(label))\n",
    "        # if you have generated your own data set and trained the networks with it:\n",
    "        # td, vd, ts, vs, projectors = dl.load(2, 'two_qubits_{}'.format(label))\n",
    "        err_i = []\n",
    "        for s in range(10):\n",
    "            name = 'two_qubits_{}_{}_{}'.format(label, s, i)\n",
    "            net = nn.Network.from_saved(name)\n",
    "            err_i.append(np.sqrt(net.run(vd, net.recon_loss)))\n",
    "        err_label.append(err_i)\n",
    "    err.append(err_label)\n",
    "err_min = np.array(err).min(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib tk\n",
    "latent_neurons = np.arange(10)\n",
    "blue_color='#000cff'\n",
    "orange_color='#ff7700'\n",
    "green_color='#3bc600'\n",
    "fig = plt.figure(figsize=(3.4, 2.1))\n",
    "ax = fig.add_subplot(111)\n",
    "width = 0.28\n",
    "ax.bar(latent_neurons - width, err_min[0], width=width, label='2-dim. subspace', color=green_color)\n",
    "ax.bar(latent_neurons, err_min[1], width=width, label='3-dim. subspace', color=blue_color)\n",
    "ax.bar(latent_neurons + width, err_min[2], width=width, label='Tom. complete', color=orange_color)\n",
    "ax.legend()\n",
    "ax.set_xticks(latent_neurons)\n",
    "ax.set_xlabel('Number of latent neurons')\n",
    "ax.set_ylabel('Error of predictions')\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "lgd=ax.legend(handles, labels,loc='upper center', bbox_to_anchor=(0.8, 1.40), shadow=True, ncol=1)\n",
    "fig.tight_layout()\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
